# ===========================
# Tiny-ImageNet FP + POT-QAT (shift-only)
# ===========================
import os, random, json
from pathlib import Path

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from datasets import load_dataset
from tqdm import tqdm
import numpy as np

# -----------------------------
# Config
# -----------------------------
SEED = 42
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_CLASSES = 200

# Data / training
BATCH_SIZE = 128
NUM_WORKERS = 2 if DEVICE.type=="cuda" else 0
PIN_MEMORY = DEVICE.type=="cuda"

EPOCHS_FP = 100
EPOCHS_POT = 20
LR_FP = 0.1
LR_POT = 5e-4
WEIGHT_DECAY = 1e-4
MIXUP_ALPHA = 0.2

# Quantization: powers of 2
POT_MIN_EXP = -5
POT_MAX_EXP = 5
POT_VALUES = [0.0] + [2.0**k for k in range(POT_MIN_EXP, POT_MAX_EXP+1)] + [-(2.0**k) for k in range(POT_MIN_EXP, POT_MAX_EXP+1)]
POT_VALUES = sorted(set(POT_VALUES))

# Saving / export
RUN_DIR = Path("./tin_pot_qat_run_hw")
RUN_DIR.mkdir(parents=True, exist_ok=True)
CKPT_BEST_FP = RUN_DIR / "best_model_fp.pth"
CKPT_FINAL_POT = RUN_DIR / "final_model_pot.pth"
EXPORT_NPZ = RUN_DIR / "weights_pot.npz"
EXPORT_TXT = RUN_DIR / "weights_pot.txt"
META_JSON  = RUN_DIR / "model_meta.json"

# -----------------------------
# TRAIN FLAG
# -----------------------------
TRAIN = True   # True → Train FP+POT, False → Only Test final model

# -----------------------------
# Repro
# -----------------------------
def set_seed(seed=SEED):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)
set_seed()

# -----------------------------
# Dataset & Dataloaders
# -----------------------------
print("Loading Tiny-ImageNet (HF)…")
ds = load_dataset("zh-plus/tiny-imagenet")

transform_train = transforms.Compose([
    transforms.Lambda(lambda img: img.convert("RGB")),
    transforms.RandomResizedCrop(64, scale=(0.7,1.0)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.1,0.1,0.1,0.05),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])
transform_val = transforms.Compose([
    transforms.Lambda(lambda img: img.convert("RGB")),
    transforms.Resize((64,64)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])
def collate_fn(batch, train=True):
    images = torch.stack([transform_train(item["image"]) if train else transform_val(item["image"]) for item in batch], dim=0)
    labels = torch.tensor([item["label"] for item in batch], dtype=torch.long)
    return images, labels

train_loader = DataLoader(ds["train"], batch_size=BATCH_SIZE, shuffle=True,
                          collate_fn=lambda b: collate_fn(b, train=True),
                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)
val_loader = DataLoader(ds["valid"], batch_size=BATCH_SIZE, shuffle=False,
                        collate_fn=lambda b: collate_fn(b, train=False),
                        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)

# -----------------------------
# FP model
# -----------------------------
class FPConvBlock(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.conv = nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=True)
        self.bn = nn.BatchNorm2d(out_ch)
        self.act = nn.ReLU(inplace=True)
    def forward(self, x): return self.act(self.bn(self.conv(x)))

class ResidualBlock(nn.Module):
    def __init__(self, ch):
        super().__init__()
        self.conv1 = FPConvBlock(ch, ch)
        self.conv2 = FPConvBlock(ch, ch)
    def forward(self, x): return x + self.conv2(self.conv1(x))

class FPCNN(nn.Module):
    def __init__(self, num_classes=NUM_CLASSES):
        super().__init__()
        self.stage1 = nn.Sequential(FPConvBlock(3,64), FPConvBlock(64,64), ResidualBlock(64), nn.MaxPool2d(2))
        self.stage2 = nn.Sequential(FPConvBlock(64,128), FPConvBlock(128,128), ResidualBlock(128), nn.MaxPool2d(2))
        self.stage3 = nn.Sequential(FPConvBlock(128,256), FPConvBlock(256,256), ResidualBlock(256), nn.MaxPool2d(2))
        self.stage4 = nn.Sequential(FPConvBlock(256,512), FPConvBlock(512,512), ResidualBlock(512), nn.MaxPool2d(2))
        self.gap = nn.AdaptiveAvgPool2d((1,1))
        self.fc = nn.Linear(512,num_classes)
    def forward(self, x):
        x = self.stage1(x); x = self.stage2(x); x = self.stage3(x); x = self.stage4(x)
        x = self.gap(x); x = torch.flatten(x,1)
        return self.fc(x)

# -----------------------------
# Utils
# -----------------------------
def evaluate(model, loader):
    model.eval(); correct,total=0,0
    with torch.no_grad():
        for imgs,labels in loader:
            imgs,labels = imgs.to(DEVICE), labels.to(DEVICE)
            pred = model(imgs).argmax(1)
            correct += (pred==labels).sum().item(); total += labels.size(0)
    return 100.0*correct/max(1,total)

def mixup_data(x, y, alpha=MIXUP_ALPHA):
    if alpha <= 0: return x, y, 1.0
    lam = np.random.beta(alpha, alpha); batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)
    mixed_x = lam*x + (1-lam)*x[index,:]; y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam
def mixup_criterion(criterion, pred, y_a, y_b, lam): return lam*criterion(pred,y_a)+(1-lam)*criterion(pred,y_b)

# Quantize tensor to nearest POT
def quantize_pot_tensor(tensor):
    with torch.no_grad():
        pot_tensor = torch.tensor(POT_VALUES, device=tensor.device, dtype=tensor.dtype)
        flat = tensor.view(-1,1)
        diff = (flat - pot_tensor.view(1,-1)).abs()
        idx = diff.argmin(dim=-1)
        tensor.copy_(pot_tensor[idx].view(tensor.shape))

# Forward pass with POT weights but FP params
class POTWrapper(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model
    def forward(self, x):
        # Save original FP weights
        orig_weights = {name: param.data.clone() for name,param in self.model.named_parameters() if "weight" in name}
        # Quantize weights to POT for forward
        for name,param in self.model.named_parameters():
            if "weight" in name:
                quantize_pot_tensor(param)
        out = self.model(x)
        # Restore FP weights for backward
        for name,param in self.model.named_parameters():
            if "weight" in name:
                param.data.copy_(orig_weights[name])
        return out

# -----------------------------
# Training pipeline
# -----------------------------
if TRAIN:
    # --- Phase 1: FP training ---
    fp_model = FPCNN().to(DEVICE)
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    optimizer = optim.SGD(fp_model.parameters(), lr=LR_FP, momentum=0.9, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_FP)
    best_acc=0.0
    print("\n=== Phase 1: Full-Precision Training ===")
    for epoch in range(1,EPOCHS_FP+1):
        fp_model.train(); running=0.0
        pbar = tqdm(train_loader, desc=f"FP Epoch {epoch}/{EPOCHS_FP}")
        for imgs, labels in pbar:
            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
            imgs, y_a, y_b, lam = mixup_data(imgs, labels)
            optimizer.zero_grad(set_to_none=True)
            logits = fp_model(imgs)
            loss = mixup_criterion(criterion, logits, y_a, y_b, lam)
            loss.backward(); optimizer.step()
            running += loss.item()
            pbar.set_postfix(loss=f"{running/(pbar.n or 1):.4f}")
        scheduler.step()
        val_acc = evaluate(fp_model,val_loader)
        print(f"[FP] Epoch {epoch} val_acc={val_acc:.2f}%")
        if val_acc>best_acc:
            best_acc=val_acc
            torch.save(fp_model.state_dict(), CKPT_BEST_FP)
            print(f"  ↳ New best {best_acc:.2f}% — saved FP checkpoint")
    print(f"FP training done. Best val_acc={best_acc:.2f}%")

    # --- Phase 2: POT fine-tuning ---
    print("\n=== Phase 2: Hard POT Quantization (Shift-only) ===")
    fp_model.load_state_dict(torch.load(CKPT_BEST_FP,map_location=DEVICE))
    pot_model = POTWrapper(fp_model).to(DEVICE)
    criterion_pot = nn.CrossEntropyLoss()
    optimizer_pot = optim.Adam(fp_model.parameters(), lr=LR_POT, weight_decay=WEIGHT_DECAY)
    best_acc_pot=0.0
    for epoch in range(1,EPOCHS_POT+1):
        fp_model.train(); running=0.0
        pbar = tqdm(train_loader, desc=f"POT Epoch {epoch}/{EPOCHS_POT}")
        for imgs, labels in pbar:
            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
            optimizer_pot.zero_grad(set_to_none=True)
            logits = pot_model(imgs)
            loss = criterion_pot(logits, labels)
            loss.backward(); optimizer_pot.step()
            running += loss.item()
            pbar.set_postfix(loss=f"{running/(pbar.n or 1):.4f}")
        # Snap FP weights to nearest POT after each epoch
        for name,param in fp_model.named_parameters():
            if "weight" in name:
                quantize_pot_tensor(param)
        val_acc = evaluate(fp_model,val_loader)
        print(f"[POT] Epoch {epoch} val_acc={val_acc:.2f}%")
        if val_acc>best_acc_pot:
            best_acc_pot=val_acc
            torch.save(fp_model.state_dict(), CKPT_FINAL_POT)
            print(f"  ↳ New best {best_acc_pot:.2f}% — saved POT checkpoint")
    print(f"POT fine-tuning done. Best val_acc={best_acc_pot:.2f}%")

    # --- Export final POT weights ---
    fp_model.load_state_dict(torch.load(CKPT_FINAL_POT,map_location=DEVICE))
    weights={}
    for name,param in fp_model.named_parameters(): weights[name]=param.detach().cpu().numpy()
    np.savez(EXPORT_NPZ,**weights)
    with open(EXPORT_TXT,"w") as f:
        for name,arr in weights.items():
            f.write(f"{name}: shape={arr.shape}\n{arr.flatten()[:20]}...\n\n")
    with open(META_JSON,"w") as f:
        json.dump({"best_acc_fp":best_acc,"best_acc_pot":best_acc_pot},f,indent=2)
    print("Final POT weights exported.")

# -----------------------------
# Test final model
# -----------------------------
else:
    print("\n=== Evaluation Mode (No Training) ===")
    model = FPCNN().to(DEVICE)
    model.load_state_dict(torch.load(CKPT_FINAL_POT,map_location=DEVICE))
    val_acc = evaluate(model,val_loader)
    print(f"[Final Quantized Model] Val Acc = {val_acc:.2f}%")
